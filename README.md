# SMPR
SMPR Language R
# Метрические алгоритмы классификации
  В задачах классификации схожие объекты
гораздо чаще лежат в одном классе, чем в разных. Если задача поддаётся
решению, то граница между классами не может «проходить повсюду»; классы
образуют компактно локализованные подмножества в пространстве объектов. Это
предположение принято называть гипотезой компактности1.

  Имеется пространство объектов X и конечное множество имён классов Y .
На множестве X задана функция расстояния ρ: X ×X → [0,∞). Существует целевая
зависимость y*: X → Y , значения которой известны только на объектах обучающей
выборки ![](https://github.com/Ismailodabashi/SMPR/blob/master/CodeCogsEqn.gif), yi = y*(xi). Требуется построить алгоритм классификации
a: X → Y , аппроксимирующий целевую зависимость y*(x) на всём множестве X.

## Метод ближайших соседей
  
**Алгоритм ближайшего соседа** (nearest neighbor, NN) является самым простым
алгоритмом классификации. Он относит классифицируемый объект u ∈ Xℓ к тому
классу, которому принадлежит ближайший обучающий объект:

![](https://github.com/Ismailodabashi/SMPR/blob/master/2.gif)
       
Обучение NN сводится к запоминанию выборки Xℓ.

Для примера использования методов классификация была взята выборка ирисов фишера по длине и ширине лепестка.

![](https://github.com/Ismailodabashi/SMPR/blob/master/IF.jpg)

**Алгоритм k ближайших соседей** (k nearest neighbors, kNN). Чтобы сгладить
влияние шумовых выбросов, будем классифицировать объекты путём голосования
по k ближайшим соседям. Каждый из соседей голосует за отнесение
объекта u к своему классу. Алгоритм относит объект u к тому классу, который
наберёт большее число голосов:

![] (https://github.com/Ismailodabashi/SMPR/blob/master/3.gif)


